{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct model\n",
    "    lstm    #Knet rnn\n",
    "    output  #final layer\n",
    "    w1      #use this weight to compute a new hidden state at each times step\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function model(embed::Int, hidden::Int, output::Int)\n",
    "    model(RNN(embed,hidden), param(output, hidden), param(20; init=xavier, atype=KnetArray{Float32}))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1\n",
    "\n",
    "gradient of w1 is computed correctly if it is used after the lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (m::model)(input)\n",
    "    ht = KnetArray(randn(Float32,20))\n",
    "    ct = KnetArray(randn(Float32,20))\n",
    "    \n",
    "    for t in 1:20\n",
    "        #take the word corresponding to timestep t\n",
    "        xt = input[:,t]\n",
    "        \n",
    "        #keep the hidden state coming in from the prev timestep unchanged\n",
    "        new_h = ht \n",
    "        new_c = ct\n",
    "                \n",
    "        #update h\n",
    "        m.lstm.h = new_h\n",
    "        m.lstm.c = new_c\n",
    "        \n",
    "        #feed in the word\n",
    "        m.lstm(xt)\n",
    "        \n",
    "        #just to reshape (20,1,1) into (20)\n",
    "        ht = reshape(m.lstm.h,20)\n",
    "        ct = reshape(m.lstm.c,20)\n",
    "    end\n",
    "\n",
    "    #use w1 after the lstm business is done, gradients for all weights return just fine\n",
    "    ht = ht .+ m.w1\n",
    "\n",
    "    return m.output * ht\n",
    "\n",
    "end\n",
    "\n",
    "(m::model)(input,output) = nll(m(input),output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(LSTM(input=100,hidden=20), P(KnetArray{Float32,2}(2,20)), P(KnetArray{Float32,1}(20)))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 classes\n",
    "model1 = model(100,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly generated data: 20 words, each is a (100) vector\n",
    "data = KnetArray(randn(Float32,100,20));\n",
    "\n",
    "#label for the single sentence (computed from the final hidden state)\n",
    "label = [1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element KnetArray{Float32,1}:\n",
       " -0.25322473\n",
       " -0.21963474"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7100831f0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(grad(J1, p)) = KnetArray{Float32,3}\n",
      "typeof(grad(J1, p)) = KnetArray{Float32,2}\n",
      "typeof(grad(J1, p)) = KnetArray{Float32,1}\n"
     ]
    }
   ],
   "source": [
    "#all 3 gradients are computed correctly\n",
    "J1 = @diff model1(data,label)\n",
    "for p in params(model1)\n",
    "    @show typeof(grad(J1, p))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2\n",
    "\n",
    "Gradient of w1 returns nothing\n",
    "\n",
    "it is used to compute new_h \n",
    "\n",
    "lstm.h is set to new_h at each timestep\n",
    "\n",
    "for some reason the gradient is not backpropagated properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (m::model)(input)\n",
    "    ht = KnetArray(randn(Float32,20))\n",
    "    ct = KnetArray(randn(Float32,20))\n",
    "    \n",
    "    for t in 1:20\n",
    "        #take the word corresponding to timestep t\n",
    "        xt = input[:,t]\n",
    "        \n",
    "        #at each iteration, use w1 to compute new hidden and cell states\n",
    "        new_h = ht + m.w1\n",
    "        new_c = ct + m.w1\n",
    "                \n",
    "        #set h to be the newly computed hidden state\n",
    "        m.lstm.h = new_h\n",
    "        m.lstm.c = new_c\n",
    "        \n",
    "        #feed in the word\n",
    "        m.lstm(xt)\n",
    "        \n",
    "        #just to reshape (20,1,1) into (20)\n",
    "        ht = reshape(m.lstm.h,20)\n",
    "        ct = reshape(m.lstm.c,20)\n",
    "    end\n",
    "    \n",
    "    return m.output * ht\n",
    "\n",
    "end\n",
    "\n",
    "(m::model)(input,output) = nll(m(input),output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606835f0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = model(100,20,2)\n",
    "model1(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(grad(J1, p)) = KnetArray{Float32,3}\n",
      "typeof(grad(J1, p)) = KnetArray{Float32,2}\n",
      "typeof(grad(J1, p)) = Nothing\n"
     ]
    }
   ],
   "source": [
    "#gradient for w1 is Nothing, it was used to compute new hidden states at each timestep\n",
    "J1 = @diff model1(data,label)\n",
    "for p in params(model1)\n",
    "    @show typeof(grad(J1, p))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
