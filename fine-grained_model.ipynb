{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet\n",
    "import Base: length, size, iterate, eltype, IteratorSize, IteratorEltype, haslength, @propagate_inbounds, repeat, rand, tail\n",
    "import .Iterators: cycle, Cycle, take, repeat\n",
    "using Plots; default(fmt=:png,ls=:auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STANFORD GLOVE EMBEDDINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"glove.42B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = readlines(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingdict = Dict()\n",
    "embeddingindex = 1\n",
    "for line in lines\n",
    "    strword = split(line)\n",
    "    strname = strword[1]\n",
    "    embeddingdict[strname] = embeddingindex\n",
    "    embeddingindex+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT TREEBANK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = open(\"sentences.txt\")\n",
    "lines1 = readlines(txt1)\n",
    "txt2 = open(\"labels.txt\")\n",
    "lines2 = readlines(txt2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = (x -> split(x)).(lines1);\n",
    "all_sentences = [(x -> lowercase(x)).(s) for s in all_sentences]\n",
    "        \n",
    "train_sentences2 = all_sentences[1:8534]\n",
    "test_sentences2 = all_sentences[8535:10744]\n",
    "val_sentences2 = all_sentences[10745:11844]\n",
    "\n",
    "train_labels = lines2[1:8534]\n",
    "train_labels = (x -> parse(Float32, x)).(train_labels)\n",
    "test_labels = lines2[8535:10744]\n",
    "val_labels = lines2[10745:11844];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mapfloat(label)\n",
    "    if (0 <= label < 0.2); return 1; end;\n",
    "    #if (0.4 <= label < 0.6); return 2; end;\n",
    "    #if (0.6 <= label <= 1.0); return 3; end;\n",
    "    if (0.2 <= label < 0.4); return 2; end;\n",
    "    if (0.4 <= label < 0.6); return 3; end;\n",
    "    if (0.6 <= label < 0.8); return 4; end;\n",
    "    if (0.8 <= label <= 1.0); return 5; end;\n",
    "end\n",
    "train_labels = (x->mapfloat(x)).(train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mapx(label)\n",
    "    if label == \"very neg\" return 1; end;\n",
    "    if label == \"neg\" return 2; end;\n",
    "    if label == \"neu\" return 3; end;\n",
    "    if label == \"pos\" return 4; end;\n",
    "    if label == \"very pos\" return 5; end;\n",
    "end\n",
    "\n",
    "function map2x(i)\n",
    "    if i == 1 return \"very negative\"; end;\n",
    "    if i == 2 return \"negative\"; end;\n",
    "    if i == 3 return \"neutral\"; end;\n",
    "    if i == 4 return \"positive\"; end;\n",
    "    if i == 5 return \"very positive\"; end;\n",
    "end\n",
    "                    \n",
    "test_labels = (x->mapx(x)).(test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sentence in all_sentences\n",
    "    for word in sentence\n",
    "        if !(word in vocab); push!(vocab, word);end\n",
    "    end\n",
    "end\n",
    "push!(vocab, \"UNK\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = Dict()\n",
    "i2w = Dict()\n",
    "dictindex = 1\n",
    "for word in vocab\n",
    "    w2i[word] = dictindex\n",
    "    i2w[dictindex] = word\n",
    "    dictindex+=1\n",
    "end\n",
    "w2i[\"UNK\"] = 19507\n",
    "i2w[19507] = \"UNK\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = [(x -> w2i[x]).(s) for s in all_sentences];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function strings_to_indices(s)\n",
    "    s = split(s)\n",
    "    out = []\n",
    "    for word in s\n",
    "        word = lowercase(word)\n",
    "        if !(word in vocab)\n",
    "            word = w2i[\"UNK\"]\n",
    "        end\n",
    "        push!(out, w2i[word])\n",
    "    end\n",
    "    hcat(out)\n",
    "end\n",
    "\n",
    "strings_to_indices(\"hey there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = all_sentences[1:8534]\n",
    "test_sentences = all_sentences[8535:10744]\n",
    "val_sentences = all_sentences[10745:11844];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength = 56\n",
    "for sentence in train_sentences\n",
    "    while length(sentence) != maxlength\n",
    "        pushfirst!(sentence, w2i[\"UNK\"])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength = 56\n",
    "for sentence in test_sentences\n",
    "    while length(sentence) != maxlength\n",
    "        pushfirst!(sentence,w2i[\"UNK\"])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCTING THE EMBEDDING MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedmatrix = []\n",
    "no_embeddings = []\n",
    "count = 0\n",
    "for word in vocab\n",
    "    if word in keys(embeddingdict)\n",
    "        wordvector = (x-> parse(Float32, x)).(split(lines[embeddingdict[word]])[2:301])\n",
    "        count += 1\n",
    "    else\n",
    "        wordvector = xavier(Float32, 300)\n",
    "        push!(no_embeddings, (word, wordvector))\n",
    "    end\n",
    "    push!(embedmatrix, hcat(wordvector))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedmatrix = hcat(embedmatrix...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(embedmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(count, \" out of \", length(vocab), \" words are in Stanford Glove Embeddings. The rest is initialized randomly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET UP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of the Model\n",
    "BATCHSIZE=5               # Number of instances in a minibatch\n",
    "EMBEDSIZE=300             # Word embedding size\n",
    "NUMHIDDEN=100             # Hidden layer size\n",
    "MAXLEN=150                # maximum size of the word sequence, pad shorter sequences, truncate longer ones\n",
    "VOCABSIZE=length(vocab)   # maximum vocabulary size, keep the most frequent 30K, map the rest to UNK token\n",
    "NUMCLASS=5                # number of output classes\n",
    "DROPOUT=0.5               # Dropout rate\n",
    "LR=0.002                  # Learning rate\n",
    "BETA_1=0.9                # Adam optimization parameter\n",
    "BETA_2=0.999              # Adam optimization parameter\n",
    "EPS=1e-08                 # Adam optimization parameter\n",
    "MAXLENGTH = 56            # Used for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = minibatch(train_sentences,train_labels,BATCHSIZE;shuffle=true)\n",
    "dtst = minibatch(test_sentences,test_labels ,BATCHSIZE)\n",
    "length(dtrn), length(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(KnetArray{Float32,2}(5,100))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = Knet.load(\"lstm46.jld2\")\n",
    "lstm46 = d1[\"lstm\"]\n",
    "embeds46 = d1[\"embeds\"]\n",
    "output46 = d1[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model struct\n",
    "struct LSTMN\n",
    "    embeds\n",
    "    lstm\n",
    "    output\n",
    "    pdrop\n",
    "    Wh\n",
    "    Wx\n",
    "    Whh\n",
    "    memory_tape\n",
    "    hidden_tape\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10Ã—5 Param{Array{Float32,2}}:\n",
       " -0.296603   -0.0889929  -0.321577   0.316929    0.10842  \n",
       " -0.29412    -0.167267   -0.111278  -0.0451668  -0.242608 \n",
       " -0.105584    0.116114    0.363484   0.0230823  -0.340264 \n",
       " -0.154036    0.303533   -0.232748   0.313824   -0.22249  \n",
       " -0.305794   -0.315736    0.225787  -0.0855627   0.127125 \n",
       " -0.050081   -0.108686    0.147441  -0.207851    0.0700677\n",
       " -0.208448    0.265458    0.270552  -0.116019    0.0671313\n",
       "  0.0497417  -0.345457    0.28639   -0.280132   -0.0079236\n",
       " -0.290121    0.363355   -0.326749   0.351861   -0.274391 \n",
       "  0.310482    0.0208921  -0.268303  -0.306375    0.184115 "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param(xavier(Float32,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model constructor\n",
    "function LSTMN(input::Int, embed::Int, hidden::Int, output::Int; pdrop=0)\n",
    "    #embeds = param(KnetArray(embedmatrix))\n",
    "    embeds = embeds46\n",
    "    #lstm = RNN(embed,hidden)\n",
    "    lstm = lstm46\n",
    "    #output = param(output, hidden)\n",
    "    output = output46\n",
    "    Wh = param(xavier(1,100))\n",
    "    Wx = param(xavier(1,300))\n",
    "    Whh = param(xavier(1,100))\n",
    "    memory_tape = KnetArray(zeros(Float32, 100,5,52))\n",
    "    hidden_tape = KnetArray(zeros(Float32, 100,5,52))\n",
    "    LSTMN(embeds, lstm, output, pdrop, Wh, Wx, Whh, memory_tape, hidden_tape)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (lstmn::LSTMN)(input)\n",
    "    embed = lstmn.embeds[:, permutedims(hcat(input...))]\n",
    "    embed = dropout(embed,lstmn.pdrop)\n",
    "    hidden = lstmn.lstm(embed)\n",
    "    hidden = dropout(hidden,lstmn.pdrop)\n",
    "    return lstmn.output * hidden[:,:,end]   \n",
    "end\n",
    "\n",
    "#=\n",
    "    embed = lstmn.embeds[:, permutedims(hcat(input...))]\n",
    "    embed = dropout(embed, lstmn.pdrop)\n",
    "    \n",
    "    #println(\"embed: \", summary(embed))\n",
    "    \n",
    "    \n",
    "    memory_tape = KnetArray(zeros(Float32,100,5,52))\n",
    "    hidden_tape = KnetArray(zeros(Float32,100,5,52))\n",
    "    \n",
    "    #println(\"memory_tape\", summary(memory_tape))\n",
    "    #println(\"hidden_tape\", summary(hidden_tape))\n",
    "\n",
    "    \n",
    "    lstmn.lstm.h = KnetArray(zeros(Float32,100,5))\n",
    "    lstmn.lstm.c = KnetArray(zeros(Float32,100,5))\n",
    "    \n",
    "    hprev = zeros(100,5)\n",
    "    xt = embed[:,:,1]\n",
    "    \n",
    "    #println(\"xt:\", summary(xt))\n",
    "    \n",
    "    lstmn.lstm(xt)\n",
    "    ht = lstmn.lstm.h[:,:,1]\n",
    "    ct = lstmn.lstm.c[:,:,1]\n",
    "    \n",
    "    #println(\"ht:\", summary(ht))\n",
    "    #println(\"ct:\", summary(ct))\n",
    "    \n",
    "    #println(\"hidden_tape:\", summary(memory_tape))\n",
    "    #println(\"memory_tape:\", summary(memory_tape))\n",
    "    #memory_tape[:,:,1] = ct\n",
    "    #hidden_tape[:,:,1] = ht\n",
    "\n",
    "    #println(\"memory_tape:\", summary(memory_tape))\n",
    "    #println(\"hidden_tape:\", summary(memory_tape))\n",
    "\n",
    "    for t in 2:52\n",
    "        #println(\"t: \",t)\n",
    "        \n",
    "        h = hidden_tape[:,:,1:t-1]\n",
    "        c = memory_tape[:,:,1:t-1]\n",
    "        \n",
    "        #println(\"h:\", summary(h))\n",
    "        #println(\"c:\", summary(c))\n",
    "\n",
    "        \n",
    "        #println(\"Wh:\", summary(lstmn.Wh))\n",
    "        dot1 = lstmn.Wh * reshape(h, 100, 5*(t-1))\n",
    "        #println(\"dot1: \", summary(dot1))\n",
    "        dot1 = reshape(dot1, (t-1), 5)\n",
    "        #println(\"dot1: \", summary(dot1))\n",
    "        \n",
    "         \n",
    "        xt = embed[:,:,t]\n",
    "        #println(\"Wx:\", summary(lstmn.Wx))\n",
    "        #println(\"xt:\", summary(xt))\n",
    "        dot2 = lstmn.Wx * xt\n",
    "        #println(\"dot2: \", summary(dot2))\n",
    "        \n",
    "        hprev = hidden_tape[:,:,t-1]\n",
    "        #println(\"Whh: \", summary(lstmn.Whh))\n",
    "        #println(\"hprev: \", summary(hprev))\n",
    "        dot3 = lstmn.Whh * hprev\n",
    "        #println(\"dot3: \", summary(dot3))\n",
    "\n",
    "        \n",
    "        at = tanh.(dot1 .+ dot2 .+ dot3)        \n",
    "        #println(\"at: \", summary(at))\n",
    "        #display(at)\n",
    "        \n",
    "        soft = softmax(at; dims=1)\n",
    "        soft = permutedims(soft)\n",
    "        soft = reshape(soft, 5*(t-1))\n",
    "        #println(\"softmax:\", summary(soft))\n",
    "        \n",
    "        h = reshape(h, 100, 5*(t-1))\n",
    "        h = permutedims(h)\n",
    "        #println(\"h:\", summary(h))\n",
    "        \n",
    "        c = reshape(c, 100, 5*(t-1))\n",
    "        c = permutedims(c)\n",
    "        #println(\"c:\", summary(c))    \n",
    "    \n",
    "                \n",
    "        new_h = soft .* h\n",
    "        new_h = reshape(new_h, 5, (t-1), 100)\n",
    "        new_h = sum(new_h; dims = 2)\n",
    "        new_h = reshape(new_h, 5,100)\n",
    "        #println(\"new_h: \", summary(new_h))\n",
    "        \n",
    "\n",
    "        new_c = soft .* c\n",
    "        new_c = reshape(new_c, 5, (t-1), 100)\n",
    "        new_c = sum(new_c; dims = 2)\n",
    "        new_c = reshape(new_c, 5,100)\n",
    "        #println(\"new_c: \", summary(new_c))\n",
    "        \n",
    "        #println(\"NEW h!!!!!:\", summary(lstmn.lstm.h))\n",
    "        #println(\"NEW c!!!!!:\", summary(lstmn.lstm.c))\n",
    "        ht = lstmn.lstm(xt)\n",
    "        #println(\"ht:\", summary(ht))\n",
    "        ct = lstmn.lstm.c[:,:,1]\n",
    "        #println(\"ct:\", summary(ct))\n",
    "        \n",
    "        #memory_tape[:,:,t] = ct\n",
    "        #println(\"memo done\")\n",
    "        \n",
    "        #hidden_tape[:,:,t] = ht\n",
    "        #println(\"hidden done\")\n",
    "        \n",
    "    end\n",
    "    \n",
    "    hidden = dropout(ht,lstmn.pdrop)\n",
    "    #println(\"hidden:\", summary(hidden))\n",
    "    #println(\"return:\", summary(lstmn.output * hidden))\n",
    "    return lstmn.output * hidden    \n",
    "end\n",
    "=#\n",
    "\n",
    "#model(input,output)\n",
    "(l::LSTMN)(input,output) = nll(l(input),output)\n",
    "#model(data)\n",
    "(l::LSTMN)(d::Knet.Data) = Knet.mean(l(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMN(VOCABSIZE,EMBEDSIZE,NUMHIDDEN,NUMCLASS,pdrop=DROPOUT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9522072f0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, y1 = first(dtrn)\n",
    "model(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4601809954751131"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    embeds\n",
    "    lstm\n",
    "    output\n",
    "    pdrop\n",
    "    Wh\n",
    "    Wx\n",
    "    Whh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"lstmn46.jld2\", \"embeds\", model.embeds, \"lstm\", model.lstm, \"output\", model.output, \"Wh\", model.Wh, \"Wx\", model.Wx, \"Whh\", model.Whh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"negative\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function userinput(lstmn::LSTMN, sentence)\n",
    "    input = strings_to_indices(sentence)\n",
    "    out = lstmn(input)[:,end]\n",
    "    maxi = 1\n",
    "    maxout = out[1]\n",
    "    for i in 1:5\n",
    "        if out[i] > maxout\n",
    "            maxi = i\n",
    "            maxout = out[i]\n",
    "        end\n",
    "    end\n",
    "    map2x(maxi)\n",
    "end\n",
    "\n",
    "userinput(model, \"I like this film very much\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fasttrain!(lstmn::LSTMN, dtrn, dtst, max_iters=500)\n",
    "    a = adam(lstmn, take(cycle(dtrn), max_iters+1);lr=LR,beta1=BETA_1,beta2=BETA_2,eps=EPS)\n",
    "    progress!(a)\n",
    "    push!(models, lstmn)\n",
    "end            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mytrain!(lstmn::LSTMN, dtrn, dtst,valid=10, max_iters=500)\n",
    "        \n",
    "    function pusher(lstmn::LSTMN,dtrn,dtst,trnloss,tstloss)\n",
    "        push!(trnloss, lstmn(dtrn))\n",
    "        push!(tstloss, lstmn(dtst))\n",
    "    end\n",
    "        \n",
    "    trnloss = []\n",
    "    tstloss = []\n",
    "    \n",
    "    takeevery(n,itr) = (x for (i,x) in enumerate(itr) if i % n == 1)            \n",
    "    #progress!(adam(model,repeat(dtrn,EPOCHS);lr=LR,beta1=BETA_1,beta2=BETA_2,eps=EPS))\n",
    "    #change the optimizer here: sgd, adam, ... @doc Knet.sgd to see other options :\n",
    "    #a = sgd(sc, take(cycle(dtrn), max_iters+1))        \n",
    "    a = adam(lstmn, take(cycle(dtrn), max_iters+1);lr=LR,beta1=BETA_1,beta2=BETA_2,eps=EPS)                   \n",
    "    b = (pusher(lstmn,dtrn,dtst,trnloss,tstloss) for x in takeevery(valid, a))\n",
    "    progress!(b)    \n",
    "    return 0:valid:max_iters, trnloss, tstloss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tgraph(lstmn::LSTMN, dtrn, dtst, valid=10, max_iters=500)\n",
    "    #Training_Accuracy = accuracy(lstmn, dtrn)\n",
    "    #Test_Accuracy = accuracy(lstmn, dtst)\n",
    "    #println(\"Training Accuracy: \", accuracy(lstmn, dtrn))\n",
    "    #println(\"Test Accuracy: \", accuracy(lstmn, dtst))\n",
    "    \n",
    "    iters, trnloss, tstloss = mytrain!(lstmn,dtrn,dtst,valid,max_iters)\n",
    "    \n",
    "    println(\"Training Accuracy: \", accuracy(lstmn, dtrn))\n",
    "    println(\"Test Accuracy: \", accuracy(lstmn, dtst))\n",
    "    \n",
    "    push!(models, (model, accuracy))\n",
    "    \n",
    "    plot(iters, [trnloss, tstloss], labels=[:trn, :tst], xlabel=\"iterations\", ylabel=\"loss\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
